{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OZMbcTFV8U4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import unittest\n",
        "from multiprocessing import Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt      # plotting routines\n",
        "from keras.models import Model       # Model type to be used\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                        # NumPy related tools\n",
        "import keras                          # high-level neural networks API and interface to TensorFlow\n",
        "import tensorflow as tf               #for numerical computation using data flow graphs\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.models import load_model, Model\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Loading Data***"
      ],
      "metadata": {
        "id": "vjSlRed50Pgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(data_dir, batch_size, img_size):\n",
        "    \"\"\"\n",
        "    Load images in batches from a directory.\n",
        "\n",
        "    Args:\n",
        "    - data_dir: string, path to the directory containing the images.\n",
        "    - batch_size: int, number of images to load in each batch.\n",
        "    - img_size: tuple, size of the images to resize to (height, width).\n",
        "\n",
        "    Returns:\n",
        "    - generator object that yields batches of images.\n",
        "    \"\"\"\n",
        "    # Get the list of image file names\n",
        "    image_files = sorted([os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith('.jpg')])\n",
        "\n",
        "    # Calculate the number of batches\n",
        "    num_batches = len(image_files) // batch_size\n",
        "\n",
        "    # Loop over the batches\n",
        "    for i in range(num_batches):\n",
        "        # Load the batch of images\n",
        "        batch_files = image_files[i*batch_size:(i+1)*batch_size]\n",
        "        batch_images = []\n",
        "        for file in batch_files:\n",
        "            image = Image.open(file)\n",
        "            image = image.resize(img_size)\n",
        "            image = np.array(image) / 255.0\n",
        "            batch_images.append(image)\n",
        "        #Conversion to numpy array of numpy arrays\n",
        "        batch_images = np.array(batch_images)\n",
        "\n",
        "        yield batch_images  #a list of image data, where each element of the list is an image array of shape (height, width, channels)\n",
        "\n",
        "################\n",
        "#Testing#\n",
        "################\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/4A_NF/Projet_4BIM/selectedData'\n",
        "\n",
        "batch_size = 32\n",
        "img_size = (64, 64)\n",
        "\n",
        "images_generator = load_images(data_dir, batch_size, img_size)\n",
        "images_list=list(images_generator)\n",
        "images_array = np.array(images_list)\n",
        "print(images_array)\n",
        "assert len(images_array[0]) ==32 \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Prints a list of size 32 where each element is a batch of images .\n",
        "Each batch has a shape of (32,256,256,3): 32 images with height and width 256 and 3 color channels (R,G,B))\n",
        "Each element of the batch is a numpy array that represents an image .\n",
        "Numbers seen in the list are RGB values of pixels of the image normalized between 0 and 1 .\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "DwQT2Bs2fqvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Autoencoder***"
      ],
      "metadata": {
        "id": "UiX3pw3g0Jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "     This code builds the encoder which is the part of the Autoencoder that constructs vectors from\n",
        "     images, compressing then initial images.\n",
        "\n",
        "\n",
        "    Args:\n",
        "      encoded_dim : the dimension of the constructed vector\n",
        "      input_shape : a tuple representing the height and width of the image\n",
        "      input_img       : the input images generated\n",
        "\n",
        "\n",
        "    Returns:\n",
        "     encoded_imgs:  the reconstructed images\n",
        " \"\"\"\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "encoded_dim = 64\n",
        "input_img = keras.Input(shape=input_shape) \n",
        "x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = keras.layers.Conv2D(encoded_dim, (3, 3), activation='relu', padding='same')(x)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "y1dD2FYJLPfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    This code builds the decoder which is the part of the Autoencoder that constructs the reconstructed\n",
        "    images from the encoded vector.\n",
        "\n",
        "    Args:\n",
        "        encoded: the encoded image vectors\n",
        "        decoded_dim: the dimension of the decoded images\n",
        "        input_shape: a tuple representing the height and width of the image\n",
        "\n",
        "    Returns:\n",
        "        decoded_imgs: the reconstructed images\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "x = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.UpSampling2D((2, 2))(x)\n",
        "x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.UpSampling2D((2, 2))(x)\n",
        "decoded = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "metadata": {
        "id": "sujogWaQ0oc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the autoencoder model:\n",
        "tf.keras.utils.plot_model(\n",
        "    autoencoder,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=70,\n",
        "    layer_range=None,\n",
        ")"
      ],
      "metadata": {
        "id": "3-x9QbhI3fEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "xhE-mJ-e3hRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test = train_test_split(images_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input images\n",
        "X_train = X_train.reshape(-1, 64, 64, 3)\n",
        "X_test = X_test.reshape(-1, 64, 64, 3)\n",
        "\n",
        "#he -1 in the reshape function is used to automatically infer the number of samples based on the size of the original dataset."
      ],
      "metadata": {
        "id": "e7Ni_Ph23hVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=100,\n",
        "                batch_size=32,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ],
      "metadata": {
        "id": "GwQuvb6rXHRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.history.history\n",
        "# Display the model's architecture\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "id": "xZBzy0C8XIH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Model Evaluation***"
      ],
      "metadata": {
        "id": "Uksphcq05MR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['val_loss'],label=\"test\")\n",
        "plt.plot(history['loss'],label=\"training\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend() #The differences of loss between the training and the test quite the same "
      ],
      "metadata": {
        "id": "aRd1ijHNXIiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many faces we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(X_test[i])\n",
        "   \n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    \n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b6fMHC5s5XJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Saving the training of the decoder ***"
      ],
      "metadata": {
        "id": "38pBgr5F38gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# extract the decoder layers from the autoencoder model\n",
        "decoder_layers = autoencoder.layers[len(autoencoder.layers)//2:]\n",
        "\n",
        "# create a new model that includes only the decoder layers\n",
        "decoder = Model(inputs=autoencoder.input, outputs=decoder_layers[-1].output)\n",
        "\n",
        "# save the decoder to a file in HDF5 format\n",
        "decoder.save('decoder_model.h5') # save decoder to a file used to save the decoder model in the Hierarchical Data Format version 5 (HDF5) file format\n"
      ],
      "metadata": {
        "id": "tUADiJ_ZXIYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***How to use this decoder part ?***"
      ],
      "metadata": {
        "id": "-TD01FE64S_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When considering encoded_img as a vector of size 64 (the actual size of the bottleneck layer).\n",
        "\n",
        "**The following code has not been tested ; it just serves as an example of the decoder usage!!**"
      ],
      "metadata": {
        "id": "CmMfdSWb4n7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = load_model('decoder_model.h5')\n",
        "generated_image = decoder.predict(encoded_img) "
      ],
      "metadata": {
        "id": "jkorY5O1XIbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Saving 2 outputs of the encoder :)***"
      ],
      "metadata": {
        "id": "T7IBlb386ahH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving the first two images from the initial set\n",
        "first2Batches= images_array[:2] # get the first two batches\n",
        "\n",
        "first2Images = first2Images.reshape(-1, 64, 64, 3)[:2]  # flatten the first two batches and extract the first two images\n",
        "print(first2Images.shape)  # should print (2, 64, 64, 3)\n",
        "\n",
        "\n",
        "\n",
        "# Predicting the encoded representation of the reshaped image\n",
        "\n",
        "\n",
        "encoded_imgs = encoder.predict(first2Images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Saving the encoded vectors to a file\n",
        "np.savetxt('encoded_vectors.txt', encoded_flat, delimiter=' ')\n",
        "\n",
        "\n",
        "#np.savetxt('encoded_vectors.txt', encoded_imgs)\n",
        "\n",
        "\n",
        "## Predicting the encoded representations of your images\n",
        "encoded_imgs = encoder.predict(first2Images)\n",
        "\n",
        "\n",
        "# Reshape the encoded_imgs array to be 2D\n",
        "encoded_imgs_flat = np.reshape(encoded_imgs, (2, -1))\n",
        "\n",
        "# Save the encoded vectors to a file\n",
        "np.savetxt('encoded_vectors.txt', encoded_imgs_flat) # separation of the two values with a space\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "jT3sTxnQ6hPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}